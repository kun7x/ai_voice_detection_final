{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"2b9bd1677a2e45a1906573d5415b2d10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70696a362311420e8dffaac73e10c32f","placeholder":"​","style":"IPY_MODEL_c0cedaf60d4b42b5920ac556259e7b9e","value":" 274/1138 [08:26&lt;28:41,  1.99s/it, loss=0.728]"}},"3825e61a532d438a8ba8fe12e106de24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70696a362311420e8dffaac73e10c32f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911836aab99f4bcaa3260b868c3fe3eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_bae61a3ca17a4468981bc19518314091","max":1138,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f03be968242d47be9e4cfc785060be79","value":274}},"b0207ee520984d13abfc593677faf5e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd6215dacd8e44c6a36a0b251530ade0","placeholder":"​","style":"IPY_MODEL_3825e61a532d438a8ba8fe12e106de24","value":"Epoch 1/5:  24%"}},"b99e828b56264bdb8f9fd277ade7384b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bae61a3ca17a4468981bc19518314091":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd69318268c94467b75c001d054b461b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0207ee520984d13abfc593677faf5e3","IPY_MODEL_911836aab99f4bcaa3260b868c3fe3eb","IPY_MODEL_2b9bd1677a2e45a1906573d5415b2d10"],"layout":"IPY_MODEL_b99e828b56264bdb8f9fd277ade7384b"}},"c0cedaf60d4b42b5920ac556259e7b9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd6215dacd8e44c6a36a0b251530ade0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f03be968242d47be9e4cfc785060be79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b0720b13","cell_type":"markdown","source":"# AI-Generated Voice Detection (Multilingual) - Kaggle\n\nThis Kaggle notebook trains a robust AI-generated voice detector following **\"Measuring the Robustness of Audio Deepfake Detectors\" (Li et al., 2025)**.\n\n**How to run on Kaggle:**\n1. Create a new Notebook (or copy this one).\n2. **Settings (right panel)**: Set **Accelerator** to **GPU** (P100 or T4). Enable **Internet** (needed to download dataset and models).\n3. **Option A – Download dataset**: Run the download + unzip cells; the dataset will be saved under `/kaggle/working/dataset`.\n4. **Option B – Use a Kaggle dataset**: Upload your dataset to Kaggle (Datasets), add it to this notebook (Add Data), then set `DATASET_ROOT` in the config cell to the path shown (e.g. `/kaggle/input/your-dataset-slug/dataset`). Skip the download and unzip cells.\n5. Run all cells. The trained model is saved under `/kaggle/working/ai_voice_detector_w2vbert` and will appear in the notebook Output for download.","metadata":{"id":"b0720b13"}},{"id":"1a1079a7","cell_type":"code","source":"# Install required packages (Kaggle)\n!pip install -q transformers datasets librosa pydub tqdm scikit-learn","metadata":{"id":"1a1079a7","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:10.921151Z","iopub.execute_input":"2026-01-29T16:40:10.921981Z","iopub.status.idle":"2026-01-29T16:40:14.647532Z","shell.execute_reply.started":"2026-01-29T16:40:10.921951Z","shell.execute_reply":"2026-01-29T16:40:14.646388Z"}},"outputs":[],"execution_count":17},{"id":"a3f857a9","cell_type":"code","source":"# Check GPU availability\nimport torch\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    DEVICE = torch.device(\"cuda\")\nelse:\n    print(\"WARNING: No GPU detected! Training will be slow.\")\n    DEVICE = torch.device(\"cpu\")\n\nprint(f\"\\nUsing device: {DEVICE}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3f857a9","outputId":"73449d3f-81f3-42d7-8148-95cae66ccb3b","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:14.649573Z","iopub.execute_input":"2026-01-29T16:40:14.649873Z","iopub.status.idle":"2026-01-29T16:40:14.656207Z","shell.execute_reply.started":"2026-01-29T16:40:14.649842Z","shell.execute_reply":"2026-01-29T16:40:14.655617Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.8.0+cu126\nCUDA available: True\nGPU: Tesla T4\nGPU Memory: 15.64 GB\n\nUsing device: cuda\n","output_type":"stream"}],"execution_count":18},{"id":"Gf2BHkNL14nm","cell_type":"code","source":"# Download dataset to Kaggle working directory (writable)\nDATASET_URL = \"https://huggingface.co/datasets/kimnamjoon0007/AI_Detection/resolve/main/dataset.zip\"\n\n!wget -q --show-progress -O /kaggle/working/dataset.zip \"{DATASET_URL}\"\nprint(\"Download complete!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gf2BHkNL14nm","outputId":"8b9b1b4c-28a4-48b8-9047-0a1fe90f5e94","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:14.657486Z","iopub.execute_input":"2026-01-29T16:40:14.657753Z","iopub.status.idle":"2026-01-29T16:40:33.662739Z","shell.execute_reply.started":"2026-01-29T16:40:14.657733Z","shell.execute_reply":"2026-01-29T16:40:33.661886Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/dat 100%[===================>] 568.05M  86.0MB/s    in 18s     \nDownload complete!\n","output_type":"stream"}],"execution_count":19},{"id":"DwIU7Gm-1-IJ","cell_type":"code","source":"# Unzip dataset into Kaggle working directory\nimport zipfile\nimport os\nimport shutil\nimport glob\n\nWORKING_DATASET = \"/kaggle/working/dataset\"\nZIP_PATH = \"/kaggle/working/dataset.zip\"\n\nif os.path.exists(WORKING_DATASET):\n    shutil.rmtree(WORKING_DATASET)\nos.makedirs(WORKING_DATASET, exist_ok=True)\n\nprint(\"Extracting dataset.zip into\", WORKING_DATASET, \"...\")\nwith zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n    zip_ref.extractall(WORKING_DATASET)\n\nprint(\"\\nExtracted contents:\")\nfor item in os.listdir(WORKING_DATASET):\n    item_path = os.path.join(WORKING_DATASET, item)\n    if os.path.isdir(item_path):\n        file_count = len([f for f in os.listdir(item_path) if os.path.isfile(os.path.join(item_path, f))])\n        print(f\"  - {item}/ ({file_count} files)\")\n    else:\n        print(f\"  - {item}\")\n\nnested_dataset = os.path.join(WORKING_DATASET, 'dataset')\nif os.path.exists(nested_dataset):\n    print(\"\\nDetected nested 'dataset' folder, reorganizing...\")\n    for item in os.listdir(nested_dataset):\n        src = os.path.join(nested_dataset, item)\n        dst = os.path.join(WORKING_DATASET, item)\n        if os.path.exists(dst):\n            shutil.rmtree(dst)\n        shutil.move(src, dst)\n    os.rmdir(nested_dataset)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"FINAL DATASET STRUCTURE:\")\nprint(\"=\"*50)\nfor root, dirs, files in os.walk(WORKING_DATASET):\n    level = root.replace(WORKING_DATASET, '').count(os.sep)\n    indent = '  ' * level\n    folder_name = os.path.basename(root) if root != WORKING_DATASET else 'dataset'\n    print(f\"{indent}{folder_name}/\")\n    if level < 2:\n        subindent = '  ' * (level + 1)\n        audio_files = [f for f in files if f.endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a'))]\n        for file in audio_files[:3]:\n            print(f\"{subindent}{file}\")\n        if len(audio_files) > 3:\n            print(f\"{subindent}... and {len(audio_files)-3} more audio files\")\n\ntotal_audio = 0\nfor ext in ['*.wav', '*.mp3', '*.flac', '*.ogg', '*.m4a']:\n    total_audio += len(glob.glob(f\"{WORKING_DATASET}/**/{ext}\", recursive=True))\nprint(f\"\\nTotal audio files found: {total_audio}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DwIU7Gm-1-IJ","outputId":"2dae4d91-145e-4674-9e4c-510effae3547","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:33.664135Z","iopub.execute_input":"2026-01-29T16:40:33.664500Z","iopub.status.idle":"2026-01-29T16:40:39.203450Z","shell.execute_reply.started":"2026-01-29T16:40:33.664460Z","shell.execute_reply":"2026-01-29T16:40:39.202589Z"}},"outputs":[{"name":"stdout","text":"Extracting dataset.zip into /kaggle/working/dataset ...\n\nExtracted contents:\n  - telugu/ (0 files)\n  - english/ (0 files)\n  - tamil/ (0 files)\n  - test/ (7 files)\n  - fake/ (30 files)\n  - real/ (30 files)\n  - hindi/ (0 files)\n  - malayalam/ (0 files)\n\n==================================================\nFINAL DATASET STRUCTURE:\n==================================================\ndataset/\n  telugu/\n    fake/\n    real/\n  english/\n    fake/\n    real/\n  tamil/\n    fake/\n    real/\n  test/\n    Hasan.wav\n    Test(Urdu Real Audio).wav\n    Test(Urdu Clone).wav\n    ... and 4 more audio files\n  fake/\n    Davis.wav\n    Henri.wav\n    Shakir.wav\n    ... and 27 more audio files\n  real/\n    clip_28.wav\n    clip_13.wav\n    clip_2.wav\n    ... and 27 more audio files\n  hindi/\n    fake/\n    real/\n  malayalam/\n    fake/\n    real/\n\nTotal audio files found: 6567\n","output_type":"stream"}],"execution_count":20},{"id":"8a1674f0","cell_type":"code","source":"# Configuration\nimport os\n\n# Root folder for the audio dataset (Kaggle: use /kaggle/working/dataset or /kaggle/input/...).\n# Expected structure:\n# dataset_root/\n#   Tamil/\n#     HUMAN/*.mp3\n#     AI_GENERATED/*.mp3\n#   English/\n#     HUMAN/*.mp3\n#     AI_GENERATED/*.mp3\n#   Hindi/...\n#   Malayalam/...\n#   Telugu/...\n\nDATASET_ROOT = \"/kaggle/working/dataset\"  # or /kaggle/input/your-dataset-slug/... if you added a Kaggle dataset\n\n# Target languages (fixed by the problem statement)\nTARGET_LANGUAGES = [\"Tamil\", \"English\", \"Hindi\", \"Malayalam\", \"Telugu\"]\n\n# Labels\nLABEL_TO_ID = {\"HUMAN\": 0, \"AI_GENERATED\": 1}\nID_TO_LABEL = {v: k for k, v in LABEL_TO_ID.items()}\n\n# Audio settings\nTARGET_SAMPLING_RATE = 16000  # 16 kHz, as used in the paper experiments\nMAX_DURATION_SECONDS = 10.0   # clips longer than this will be randomly cropped during training\n\n# Model and training hyperparameters\nMODEL_NAME = \"facebook/wav2vec2-large-xlsr-53\"  # Wave2Vec2BERT backbone\nBATCH_SIZE = 8\nNUM_EPOCHS = 5\nLEARNING_RATE = 1e-5\nWARMUP_RATIO = 0.1\nWEIGHT_DECAY = 0.01\n\nOUTPUT_DIR = \"/kaggle/working/ai_voice_detector_w2vbert\"  # saved model will appear in Notebook Output\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(\"Config loaded.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8a1674f0","outputId":"61a14eee-42c1-4ce6-f61f-2a1fd58800d5","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:39.205766Z","iopub.execute_input":"2026-01-29T16:40:39.206118Z","iopub.status.idle":"2026-01-29T16:40:39.212626Z","shell.execute_reply.started":"2026-01-29T16:40:39.206093Z","shell.execute_reply":"2026-01-29T16:40:39.211981Z"}},"outputs":[{"name":"stdout","text":"Config loaded.\n","output_type":"stream"}],"execution_count":21},{"id":"a6a5ae77","cell_type":"code","source":"# Data discovery and index construction\n\nimport glob\nfrom dataclasses import dataclass\nfrom typing import List\n\n@dataclass\nclass AudioSample:\n    path: str\n    language: str\n    label: str  # \"HUMAN\" or \"AI_GENERATED\"\n\n\ndef discover_dataset(dataset_root: str) -> List[AudioSample]:\n    \"\"\"\n    Scan the dataset directory and build an index of (path, language, label).\n\n    Assumes structure like:\n      dataset/\n        english/\n          human/ or real/\n          ai/ or fake/ or ai_generated/\n        tamil/\n        ...\n\n    Folder names can be lowercase; we normalize them here.\n    \"\"\"\n    samples: List[AudioSample] = []\n\n    # Possible on-disk names for each canonical label\n    label_dir_map = {\n        \"HUMAN\": [\"HUMAN\", \"human\", \"real\", \"Real\"],\n        \"AI_GENERATED\": [\"AI_GENERATED\", \"ai_generated\", \"ai\", \"fake\", \"Fake\"],\n    }\n\n    for language in TARGET_LANGUAGES:\n        # Most HF zips use lowercase language folder names\n        lang_dir = os.path.join(dataset_root, language.lower())\n        if not os.path.isdir(lang_dir):\n            print(f\"[WARN] Language folder not found: {lang_dir}\")\n            continue\n\n        for canonical_label, dir_names in label_dir_map.items():\n            label_found = False\n            for dn in dir_names:\n                label_dir = os.path.join(lang_dir, dn)\n                if os.path.isdir(label_dir):\n                    pattern = os.path.join(label_dir, \"**\", \"*.mp3\")\n                    for path in glob.glob(pattern, recursive=True):\n                        samples.append(\n                            AudioSample(path=path, language=language, label=canonical_label)\n                        )\n                    label_found = True\n            if not label_found:\n                print(f\"[WARN] No folder for label {canonical_label} under {lang_dir}\")\n\n    print(f\"Discovered {len(samples)} audio files across {len(TARGET_LANGUAGES)} languages.\")\n    return samples\n\n\nall_samples = discover_dataset(DATASET_ROOT)\n\n# Optional: peek at a few samples\nfor s in all_samples[:5]:\n    print(s)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6a5ae77","outputId":"1f91e0ce-bb75-4cc6-f350-f0b66075dc26","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:39.213535Z","iopub.execute_input":"2026-01-29T16:40:39.213900Z","iopub.status.idle":"2026-01-29T16:40:39.250966Z","shell.execute_reply.started":"2026-01-29T16:40:39.213877Z","shell.execute_reply":"2026-01-29T16:40:39.250154Z"}},"outputs":[{"name":"stdout","text":"Discovered 6500 audio files across 5 languages.\nAudioSample(path='/kaggle/working/dataset/tamil/real/3645.mp3', language='Tamil', label='HUMAN')\nAudioSample(path='/kaggle/working/dataset/tamil/real/26525.mp3', language='Tamil', label='HUMAN')\nAudioSample(path='/kaggle/working/dataset/tamil/real/4603.mp3', language='Tamil', label='HUMAN')\nAudioSample(path='/kaggle/working/dataset/tamil/real/15771.mp3', language='Tamil', label='HUMAN')\nAudioSample(path='/kaggle/working/dataset/tamil/real/23214.mp3', language='Tamil', label='HUMAN')\n","output_type":"stream"}],"execution_count":22},{"id":"82da984b-aabf-4bc6-9ec7-1a482afdcb66","cell_type":"code","source":"# Patched load_audio that handles corrupted files\ndef load_audio(path: str, target_sr: int = TARGET_SAMPLING_RATE) -> torch.Tensor:\n    \"\"\"Load an audio file and resample to target_sr, mono.\"\"\"\n    try:\n        audio_segment = AudioSegment.from_file(path)\n    except Exception as e:\n        print(f\"[WARN] Corrupted file skipped: {path}\")\n        # Return 0.5s of silence as a placeholder\n        return torch.zeros(1, int(target_sr * 0.5))\n    \n    samples = np.array(audio_segment.get_array_of_samples()).astype(np.float32)\n    channels = audio_segment.channels\n    if channels > 1:\n        samples = samples.reshape(-1, channels).mean(axis=1)\n    samples /= 32767.0\n    sr = audio_segment.frame_rate\n    if sr != target_sr:\n        samples = librosa.resample(samples, orig_sr=sr, target_sr=target_sr)\n    return torch.from_numpy(samples).unsqueeze(0)\n\nprint(\"Patched load_audio function - corrupted files will be replaced with silence.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:39.251937Z","iopub.execute_input":"2026-01-29T16:40:39.252417Z","iopub.status.idle":"2026-01-29T16:40:39.258464Z","shell.execute_reply.started":"2026-01-29T16:40:39.252384Z","shell.execute_reply":"2026-01-29T16:40:39.257904Z"}},"outputs":[{"name":"stdout","text":"Patched load_audio function - corrupted files will be replaced with silence.\n","output_type":"stream"}],"execution_count":23},{"id":"35fbe854","cell_type":"code","source":"# Train/validation/test split\n\nfrom sklearn.model_selection import train_test_split\n\nif len(all_samples) == 0:\n    raise RuntimeError(\"No audio files found. Please mount/upload your dataset and set DATASET_ROOT correctly.\")\n\n# Convert to simple lists for splitting\npaths = [s.path for s in all_samples]\nlabels = [LABEL_TO_ID[s.label] for s in all_samples]\nlanguages = [s.language for s in all_samples]\n\n# Stratify by label to keep AI/HUMAN balance\ntrain_paths, temp_paths, train_labels, temp_labels, train_langs, temp_langs = train_test_split(\n    paths, labels, languages, test_size=0.3, random_state=42, stratify=labels\n)\n\nval_paths, test_paths, val_labels, test_labels, val_langs, test_langs = train_test_split(\n    temp_paths, temp_labels, temp_langs, test_size=0.5, random_state=42, stratify=temp_labels\n)\n\nprint(f\"Train: {len(train_paths)} | Val: {len(val_paths)} | Test: {len(test_paths)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35fbe854","outputId":"09081f28-689a-4b13-83e2-40b8ac73a551","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:39.259280Z","iopub.execute_input":"2026-01-29T16:40:39.259684Z","iopub.status.idle":"2026-01-29T16:40:39.287630Z","shell.execute_reply.started":"2026-01-29T16:40:39.259653Z","shell.execute_reply":"2026-01-29T16:40:39.286861Z"}},"outputs":[{"name":"stdout","text":"Train: 4550 | Val: 975 | Test: 975\n","output_type":"stream"}],"execution_count":24},{"id":"d1c8f945","cell_type":"code","source":"# Robustness-oriented audio augmentations (following the paper)\n\nimport random\nimport io\nimport librosa\nimport numpy as np\nimport torch\nfrom pydub import AudioSegment\n\ndef load_audio(path: str, target_sr: int = TARGET_SAMPLING_RATE) -> torch.Tensor:\n    \"\"\"Load an audio file and resample to target_sr, mono, using pydub + librosa.\n\n    This avoids backend issues with mp3 decoding in soundfile/librosa and works\n    reliably for the dataset's MP3 files.\n    \"\"\"\n    audio_segment = AudioSegment.from_file(path)\n    samples = np.array(audio_segment.get_array_of_samples()).astype(np.float32)\n    channels = audio_segment.channels\n    if channels > 1:\n        samples = samples.reshape(-1, channels).mean(axis=1)\n    samples /= 32767.0\n    sr = audio_segment.frame_rate\n    if sr != target_sr:\n        samples = librosa.resample(samples, orig_sr=sr, target_sr=target_sr)\n    return torch.from_numpy(samples).unsqueeze(0)\n\n\ndef random_crop(waveform: torch.Tensor, max_duration: float, sr: int) -> torch.Tensor:\n    max_len = int(max_duration * sr)\n    if waveform.shape[1] <= max_len:\n        return waveform\n    start = random.randint(0, waveform.shape[1] - max_len)\n    return waveform[:, start:start + max_len]\n\n\n# 1. Noise perturbation (Gaussian / background-like noise)\n\ndef add_gaussian_noise(waveform: torch.Tensor, snr_db: float = 20.0) -> torch.Tensor:\n    \"\"\"Add Gaussian noise at a target SNR, as in the paper's noise perturbations section.\"\"\"\n    signal_power = waveform.pow(2).mean()\n    snr_linear = 10 ** (snr_db / 10)\n    noise_power = signal_power / snr_linear\n    noise = torch.randn_like(waveform) * torch.sqrt(noise_power)\n    return waveform + noise\n\n\n# 2. Pitch shifting (spectral modification)\n\ndef pitch_shift(waveform: torch.Tensor, sr: int, n_steps_range=(-2.0, 2.0)) -> torch.Tensor:\n    \"\"\"Apply pitch shifting using librosa, following the paper's challenging pitch-shift corruption.\"\"\"\n    y = waveform.squeeze(0).cpu().numpy()\n    n_steps = random.uniform(*n_steps_range)\n    y_shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n    return torch.from_numpy(y_shifted).unsqueeze(0)\n\n\n# 3. Time stretching (temporal modification)\n\ndef time_stretch(waveform: torch.Tensor, sr: int, rate_range=(0.8, 1.2)) -> torch.Tensor:\n    \"\"\"Apply time stretching, another corruption highlighted as particularly harmful in the paper.\"\"\"\n    y = waveform.squeeze(0).cpu().numpy()\n    rate = random.uniform(*rate_range)\n    y_stretched = librosa.effects.time_stretch(y, rate=rate)\n    return torch.from_numpy(y_stretched).unsqueeze(0)\n\n\n# 4. MP3 compression (proxy for codec-based corruption like MP3/Opus/Encodec)\n\ndef mp3_compress_decompress(waveform: torch.Tensor, sr: int, bitrate: str = \"32k\") -> torch.Tensor:\n    \"\"\"Simulate lossy codec corruption by round-tripping through MP3 at a low bitrate.\n\n    The paper shows that traditional and neural codecs (MP3, Opus, Encodec, DAC, FACodec, AudioDec)\n    severely hurt detectors despite high perceptual quality. This augmentation mimics that effect.\n    \"\"\"\n    # Convert tensor to 16-bit PCM bytes\n    y = waveform.squeeze(0).cpu().numpy()\n    audio_segment = AudioSegment(\n        (y * 32767).astype(np.int16).tobytes(),\n        frame_rate=sr,\n        sample_width=2,\n        channels=1,\n    )\n\n    # Export to MP3 in-memory\n    buf = io.BytesIO()\n    audio_segment.export(buf, format=\"mp3\", bitrate=bitrate)\n    buf.seek(0)\n\n    # Read back\n    compressed = AudioSegment.from_file(buf, format=\"mp3\")\n    samples = np.array(compressed.get_array_of_samples()).astype(np.float32) / 32767.0\n    return torch.from_numpy(samples).unsqueeze(0)\n\n\ndef apply_random_corruption(waveform: torch.Tensor, sr: int) -> torch.Tensor:\n    \"\"\"Randomly apply one of the corruptions (or none) during training.\n\n    This follows the paper's robustness enhancement strategy: mix clean and corrupted\n    examples, with challenging corruptions like pitch shift, time stretch, and codec\n    compression to improve generalization.\n    \"\"\"\n    # Keep some samples clean\n    if random.random() < 0.3:\n        return waveform\n\n    ops = [\n        lambda x: add_gaussian_noise(x, snr_db=random.choice([10.0, 20.0, 30.0])),\n        lambda x: pitch_shift(x, sr),\n        lambda x: time_stretch(x, sr),\n        lambda x: mp3_compress_decompress(x, sr, bitrate=random.choice([\"32k\", \"64k\", \"96k\"])),\n    ]\n    op = random.choice(ops)\n    try:\n        return op(waveform)\n    except Exception as e:\n        # Fallback to original if an augmentation fails (e.g., very short clips)\n        print(f\"[AUGMENT WARN] {e}\")\n        return waveform","metadata":{"id":"d1c8f945","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:39.288621Z","iopub.execute_input":"2026-01-29T16:40:39.288884Z","iopub.status.idle":"2026-01-29T16:40:39.315693Z","shell.execute_reply.started":"2026-01-29T16:40:39.288861Z","shell.execute_reply":"2026-01-29T16:40:39.314889Z"}},"outputs":[],"execution_count":25},{"id":"8a244df5","cell_type":"code","source":"# PyTorch Dataset and DataLoader\n\nfrom torch.utils.data import Dataset, DataLoader\n\n\nclass AIDeepfakeDataset(Dataset):\n    \"\"\"Binary AI/HUMAN detector dataset with optional corruption-based augmentation.\"\"\"\n\n    def __init__(self, paths, labels, languages, augment: bool = False):\n        self.paths = list(paths)\n        self.labels = list(labels)\n        self.languages = list(languages)\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        path = self.paths[idx]\n        label = self.labels[idx]\n        language = self.languages[idx]\n\n        waveform = load_audio(path, target_sr=TARGET_SAMPLING_RATE)\n        waveform = random_crop(waveform, MAX_DURATION_SECONDS, TARGET_SAMPLING_RATE)\n\n        if self.augment:\n            waveform = apply_random_corruption(waveform, TARGET_SAMPLING_RATE)\n\n        return {\n            \"input_values\": waveform.squeeze(0),  # (T,)\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"language\": language,\n        }\n\n\ntrain_dataset = AIDeepfakeDataset(train_paths, train_labels, train_langs, augment=True)\nval_dataset = AIDeepfakeDataset(val_paths, val_labels, val_langs, augment=False)\ntest_dataset = AIDeepfakeDataset(test_paths, test_labels, test_langs, augment=False)\n\nprint(f\"Train samples: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8a244df5","outputId":"a2f04853-1e2f-46e1-871a-1ae5eae7d3b7","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:39.316762Z","iopub.execute_input":"2026-01-29T16:40:39.317041Z","iopub.status.idle":"2026-01-29T16:40:39.325063Z","shell.execute_reply.started":"2026-01-29T16:40:39.317001Z","shell.execute_reply":"2026-01-29T16:40:39.324397Z"}},"outputs":[{"name":"stdout","text":"Train samples: 4550 | Val: 975 | Test: 975\n","output_type":"stream"}],"execution_count":26},{"id":"af23d00e","cell_type":"code","source":"from transformers import AutoFeatureExtractor, Wav2Vec2Model\n\nfeature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)\n\nbackbone = Wav2Vec2Model.from_pretrained(MODEL_NAME)\nbackbone.to(DEVICE)\n\nprint(\"Backbone loaded.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"af23d00e","outputId":"78942aec-3b67-4b7a-dac0-1c7187aea1f1","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:40:39.325962Z","iopub.execute_input":"2026-01-29T16:40:39.326205Z","iopub.status.idle":"2026-01-29T16:41:13.424922Z","shell.execute_reply.started":"2026-01-29T16:40:39.326170Z","shell.execute_reply":"2026-01-29T16:41:13.421668Z"}},"outputs":[{"name":"stderr","text":"2026-01-29 16:40:50.650545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769704850.897562      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769704850.986153      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769704851.622741      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769704851.622801      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769704851.622804      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769704851.622807      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dea0ed6d5e84b9fbdbf9b3f11f59cf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11681eabd9fe4e13b97eec897ca2981f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0d629360d645e3b8ba64febfd4dd8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43865d0bf852419caeb4be7703290831"}},"metadata":{}},{"name":"stdout","text":"Backbone loaded.\n","output_type":"stream"}],"execution_count":27},{"id":"63b796ea","cell_type":"code","source":"# Model head: utterance-level classifier on top of Wav2Vec2\n\nimport torch.nn as nn\n\nclass W2VBertDeepfakeDetector(nn.Module):\n    \"\"\"Wave2Vec2-based deepfake detector using a foundation speech model.\"\"\"\n\n    def __init__(self, backbone, num_labels: int = 2):\n        super().__init__()\n        self.backbone = backbone\n        hidden_size = backbone.config.hidden_size\n        self.dropout = nn.Dropout(0.1)\n        self.classifier = nn.Linear(hidden_size, num_labels)\n\n    def forward(self, input_values, attention_mask=None, labels=None):\n        # input_values is already a padded batch of raw waveforms: (batch, T)\n        # from collate_fn. We feed it directly to Wav2Vec2Model.\n\n        input_vals = input_values.to(DEVICE)  # (B, T)\n\n        # Wav2Vec2Model expects input_values (float PCM in [-1, 1])\n        outputs = self.backbone(input_values=input_vals, attention_mask=attention_mask)\n\n        hidden_states = outputs.last_hidden_state  # (batch, seq_len, hidden)\n        pooled = hidden_states.mean(dim=1)\n        pooled = self.dropout(pooled)\n        logits = self.classifier(pooled)\n\n        loss = None\n        if labels is not None:\n            labels = labels.to(DEVICE)\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(logits, labels)\n\n        return {\"loss\": loss, \"logits\": logits}\n\n\nmodel = W2VBertDeepfakeDetector(backbone, num_labels=2).to(DEVICE)\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\n    print(f\"Using {torch.cuda.device_count()} GPUs (DataParallel).\")\nprint(\"Full model ready.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63b796ea","outputId":"1eb61480-dfe8-4008-e5aa-9b8e39385615","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:41:13.426275Z","iopub.execute_input":"2026-01-29T16:41:13.427108Z","iopub.status.idle":"2026-01-29T16:41:13.459445Z","shell.execute_reply.started":"2026-01-29T16:41:13.427055Z","shell.execute_reply":"2026-01-29T16:41:13.458317Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs (DataParallel).\nFull model ready.\n","output_type":"stream"}],"execution_count":28},{"id":"1b7d559c","cell_type":"code","source":"# Data collator\n\nfrom typing import Dict, Any\n\n\ndef collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n    input_values = [item[\"input_values\"] for item in batch]\n    labels = torch.stack([item[\"label\"] for item in batch])\n    languages = [item[\"language\"] for item in batch]\n\n    # We will pass raw waveforms into the model, which will internally use the\n    # same feature extractor as the paper (Mel-like features for Wav2Vec2BERT).\n    padded = nn.utils.rnn.pad_sequence(input_values, batch_first=True)\n\n    return {\n        \"input_values\": padded.to(DEVICE),\n        \"labels\": labels.to(DEVICE),\n        \"languages\": languages,\n    }\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n\nprint(\"DataLoaders ready.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b7d559c","outputId":"3495998c-a300-4bf9-b0fc-73b1fd82ac9d","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:41:13.461299Z","iopub.execute_input":"2026-01-29T16:41:13.461747Z","iopub.status.idle":"2026-01-29T16:41:13.482850Z","shell.execute_reply.started":"2026-01-29T16:41:13.461703Z","shell.execute_reply":"2026-01-29T16:41:13.481616Z"}},"outputs":[{"name":"stdout","text":"DataLoaders ready.\n","output_type":"stream"}],"execution_count":29},{"id":"21acee70","cell_type":"code","source":"# Optimizer, scheduler, and metrics (Accuracy, AUROC, EER as in the paper)\n\nfrom transformers import get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\nnum_training_steps = NUM_EPOCHS * len(train_loader)\nnum_warmup_steps = int(WARMUP_RATIO * num_training_steps)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=num_training_steps,\n)\n\n\ndef compute_eer(y_true, y_scores):\n    \"\"\"Compute Equal Error Rate (EER), matching the paper's main metric.\n\n    We sweep thresholds over [0, 1] on the predicted probability of AI_GENERATED.\n    \"\"\"\n    y_true = np.array(y_true)\n    y_scores = np.array(y_scores)\n\n    # thresholds between 0 and 1\n    thresholds = np.linspace(0, 1, 200)\n    fprs = []\n    fnrs = []\n\n    for th in thresholds:\n        y_pred = (y_scores >= th).astype(int)\n        tp = np.sum((y_true == 1) & (y_pred == 1))\n        tn = np.sum((y_true == 0) & (y_pred == 0))\n        fp = np.sum((y_true == 0) & (y_pred == 1))\n        fn = np.sum((y_true == 1) & (y_pred == 0))\n\n        fpr = fp / (fp + tn + 1e-8)\n        fnr = fn / (fn + tp + 1e-8)\n        fprs.append(fpr)\n        fnrs.append(fnr)\n\n    fprs = np.array(fprs)\n    fnrs = np.array(fnrs)\n    diffs = np.abs(fprs - fnrs)\n    idx = np.argmin(diffs)\n    eer = (fprs[idx] + fnrs[idx]) / 2.0\n    return float(eer)\n\n\nprint(\"Optimizer, scheduler, and metrics ready.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21acee70","outputId":"f8a3e9d7-c242-4e81-d0ff-8e7cc9ec244f","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:41:13.490200Z","iopub.execute_input":"2026-01-29T16:41:13.490652Z","iopub.status.idle":"2026-01-29T16:41:13.622159Z","shell.execute_reply.started":"2026-01-29T16:41:13.490602Z","shell.execute_reply":"2026-01-29T16:41:13.621031Z"}},"outputs":[{"name":"stdout","text":"Optimizer, scheduler, and metrics ready.\n","output_type":"stream"}],"execution_count":30},{"id":"667b2066","cell_type":"code","source":"# Training loop (with validation using Accuracy, AUROC, EER)\n\nfrom tqdm.auto import tqdm\n\n\ndef evaluate(loader, desc=\"Val\"):\n    model.eval()\n    all_labels = []\n    all_probs_ai = []  # probability of AI_GENERATED (class 1)\n\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=desc):\n            outputs = model(input_values=batch[\"input_values\"], labels=None)\n            logits = outputs[\"logits\"]\n            probs = torch.softmax(logits, dim=-1)[:, 1]  # P(AI_GENERATED)\n\n            all_labels.extend(batch[\"labels\"].cpu().numpy().tolist())\n            all_probs_ai.extend(probs.cpu().numpy().tolist())\n\n    # Use 0.5 threshold for accuracy, as in typical binary classification\n    preds = (np.array(all_probs_ai) >= 0.5).astype(int)\n    acc = accuracy_score(all_labels, preds)\n\n    try:\n        auroc = roc_auc_score(all_labels, all_probs_ai)\n    except ValueError:\n        auroc = float(\"nan\")  # e.g., only one class present\n\n    eer = compute_eer(all_labels, all_probs_ai)\n    return {\"accuracy\": acc, \"auroc\": auroc, \"eer\": eer}\n\n\nbest_val_eer = 1.0\n\nfor epoch in range(1, NUM_EPOCHS + 1):\n    model.train()\n    train_loss = 0.0\n\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\")\n    for batch in pbar:\n        optimizer.zero_grad()\n\n        outputs = model(input_values=batch[\"input_values\"], labels=batch[\"labels\"])\n        loss = outputs[\"loss\"]\n\n        # Fix for DataParallel: reduce loss to scalar if needed\n        if loss.dim() > 0:\n            loss = loss.mean()\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n\n        train_loss += loss.item()\n        pbar.set_postfix({\"loss\": loss.item()})\n\n    train_loss /= max(1, len(train_loader))\n\n    # Validation\n    metrics = evaluate(val_loader, desc=\"Val\")\n    print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, val_acc={metrics['accuracy']:.4f}, \"\n          f\"val_auroc={metrics['auroc']:.4f}, val_eer={metrics['eer']:.4f}\")\n\n    # Save best model by EER (lower is better), as in the paper\n    if metrics[\"eer\"] < best_val_eer:\n        best_val_eer = metrics[\"eer\"]\n        state_to_save = model.module.state_dict() if hasattr(model, \"module\") else model.state_dict()\n        torch.save(state_to_save, os.path.join(OUTPUT_DIR, \"best_model.pt\"))\n        print(\"Saved new best model (by EER).\")\n\nprint(\"Training complete.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":640,"referenced_widgets":["bd69318268c94467b75c001d054b461b","b0207ee520984d13abfc593677faf5e3","911836aab99f4bcaa3260b868c3fe3eb","2b9bd1677a2e45a1906573d5415b2d10","b99e828b56264bdb8f9fd277ade7384b","dd6215dacd8e44c6a36a0b251530ade0","3825e61a532d438a8ba8fe12e106de24","bae61a3ca17a4468981bc19518314091","f03be968242d47be9e4cfc785060be79","70696a362311420e8dffaac73e10c32f","c0cedaf60d4b42b5920ac556259e7b9e"]},"id":"667b2066","outputId":"9c76a3cc-ae1c-410c-82ba-3653b9881d25","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T16:44:47.606752Z","iopub.execute_input":"2026-01-29T16:44:47.607466Z","iopub.status.idle":"2026-01-29T17:03:25.983042Z","shell.execute_reply.started":"2026-01-29T16:44:47.607435Z","shell.execute_reply":"2026-01-29T17:03:25.981596Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/5:   0%|          | 0/569 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6c0bed6a1674351a38b14a40a35f166"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCouldntDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3231708890.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch}/{NUM_EPOCHS}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/2253951813.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_SAMPLING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_DURATION_SECONDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTARGET_SAMPLING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/1408906303.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(path, target_sr)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mreliably\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mMP3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \"\"\"\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0maudio_segment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_segment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_segment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             raise CouldntDecodeError(\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \"Decoding failed. ffmpeg returned error code: {0}\\n\\nOutput from ffmpeg/avlib:\\n\\n{1}\".format(\n\u001b[1;32m    775\u001b[0m                     p.returncode, p_err.decode(errors='ignore') ))\n","\u001b[0;31mCouldntDecodeError\u001b[0m: Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[mp3 @ 0x584dde1b44c0] Format mp3 detected only with low score of 1, misdetection possible!\n[mp3 @ 0x584dde1b44c0] Failed to read frame size: Could not seek to 1026.\n/kaggle/working/dataset/tamil/fake/tamil_0330.mp3: Invalid argument\n"],"ename":"CouldntDecodeError","evalue":"Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[mp3 @ 0x584dde1b44c0] Format mp3 detected only with low score of 1, misdetection possible!\n[mp3 @ 0x584dde1b44c0] Failed to read frame size: Could not seek to 1026.\n/kaggle/working/dataset/tamil/fake/tamil_0330.mp3: Invalid argument\n","output_type":"error"}],"execution_count":32},{"id":"63922ac9","cell_type":"code","source":"# Final evaluation on the held-out test set\n\n# Load best model (by validation EER)\nstate = torch.load(os.path.join(OUTPUT_DIR, \"best_model.pt\"), map_location=DEVICE)\nif hasattr(model, \"module\"):\n    model.module.load_state_dict(state)\nelse:\n    model.load_state_dict(state)\nmodel.to(DEVICE)\n\nmetrics_test = evaluate(test_loader, desc=\"Test\")\nprint(\"Test metrics:\")\nprint(f\"  Accuracy: {metrics_test['accuracy']:.4f}\")\nprint(f\"  AUROC:    {metrics_test['auroc']:.4f}\")\nprint(f\"  EER:      {metrics_test['eer']:.4f}\")","metadata":{"id":"63922ac9","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T17:03:25.983825Z","iopub.status.idle":"2026-01-29T17:03:25.984222Z","shell.execute_reply.started":"2026-01-29T17:03:25.984014Z","shell.execute_reply":"2026-01-29T17:03:25.984038Z"}},"outputs":[],"execution_count":null},{"id":"4424918c","cell_type":"code","source":"# Save model + feature extractor for deployment\n\nfrom transformers import Wav2Vec2Model\n\n# Save backbone configuration and feature extractor alongside the fine-tuned head weights\nbackbone.save_pretrained(OUTPUT_DIR)\nfeature_extractor.save_pretrained(OUTPUT_DIR)\n\nprint(f\"Saved backbone and feature extractor to {OUTPUT_DIR}\")\nprint(\"For deployment, also keep 'best_model.pt' (classifier head + backbone weights).\")","metadata":{"id":"4424918c","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T17:03:25.985573Z","iopub.status.idle":"2026-01-29T17:03:25.986047Z","shell.execute_reply.started":"2026-01-29T17:03:25.985815Z","shell.execute_reply":"2026-01-29T17:03:25.985846Z"}},"outputs":[],"execution_count":null},{"id":"0bd5b0ef","cell_type":"code","source":"# Inference helper aligned with the problem statement (for API integration later)\n\nimport base64\nimport io\nimport numpy as np\nimport librosa\nfrom pydub import AudioSegment\n\n\ndef load_model_for_inference(model_dir: str):\n    \"\"\"Reload the fine-tuned model + feature extractor for inference.\n\n    This is what your API server should do on startup.\n    \"\"\"\n    feat_extractor = AutoFeatureExtractor.from_pretrained(model_dir)\n    backb = Wav2Vec2Model.from_pretrained(model_dir)\n    det = W2VBertDeepfakeDetector(backb, num_labels=2)\n    det.load_state_dict(torch.load(os.path.join(model_dir, \"best_model.pt\"), map_location=DEVICE))\n    det.to(DEVICE)\n    det.eval()\n    return feat_extractor, det\n\n\ndef classify_base64_mp3(audio_base64: str, language: str, model_dir: str = OUTPUT_DIR):\n    \"\"\"Classify a single Base64-encoded MP3 as AI_GENERATED or HUMAN.\n\n    This mirrors the problem statement:\n    - Input: one Base64 MP3 and a language (Tamil/English/Hindi/Malayalam/Telugu)\n    - Output: classification, confidence score, and a short explanation.\n    \"\"\"\n    if language not in TARGET_LANGUAGES:\n        raise ValueError(f\"Unsupported language: {language}. Must be one of {TARGET_LANGUAGES}.\")\n\n    feature_extractor_inf, model_inf = load_model_for_inference(model_dir)\n\n    # Decode base64 to raw bytes\n    audio_bytes = base64.b64decode(audio_base64)\n    buf = io.BytesIO(audio_bytes)\n\n    # Decode MP3 bytes with pydub\n    audio_segment = AudioSegment.from_file(buf, format=\"mp3\")\n    samples = np.array(audio_segment.get_array_of_samples()).astype(np.float32) / 32767.0\n    sr = audio_segment.frame_rate\n\n    # Resample to TARGET_SAMPLING_RATE if needed (librosa)\n    if sr != TARGET_SAMPLING_RATE:\n        samples = librosa.resample(samples, orig_sr=sr, target_sr=TARGET_SAMPLING_RATE)\n\n    waveform = torch.from_numpy(samples).unsqueeze(0)\n    waveform = random_crop(waveform, MAX_DURATION_SECONDS, TARGET_SAMPLING_RATE)\n\n    # Run through model\n    with torch.no_grad():\n        features = feature_extractor_inf(\n            waveform.squeeze(0),\n            sampling_rate=TARGET_SAMPLING_RATE,\n            return_tensors=\"pt\",\n            padding=True,\n        )\n        # For Wav2Vec2* models, the feature extractor outputs \"input_values\"\n        input_vals = features[\"input_values\"].to(DEVICE)\n        attention_mask = features.get(\"attention_mask\")\n        if attention_mask is not None:\n            attention_mask = attention_mask.to(DEVICE)\n\n        outputs = model_inf.backbone(input_values=input_vals, attention_mask=attention_mask)\n        hidden_states = outputs.last_hidden_state\n        pooled = hidden_states.mean(dim=1)\n        logits = model_inf.classifier(pooled)\n        probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n\n    prob_human = float(probs[0])\n    prob_ai = float(probs[1])\n\n    if prob_ai >= prob_human:\n        classification = \"AI_GENERATED\"\n        confidence = prob_ai\n        explanation = (\n            \"Model detected spectral and temporal artifacts consistent with AI-synthesized speech, \"\n            \"and these patterns remained distinguishable even under compression- and pitch/time-based \"\n            \"corruptions similar to those studied in the robustness paper.\"\n        )\n    else:\n        classification = \"HUMAN\"\n        confidence = prob_human\n        explanation = (\n            \"Signal characteristics (prosody, spectral detail, and temporal variation) align with \"\n            \"human speech patterns and do not exhibit the codec- and modification-sensitive artifacts \"\n            \"associated with AI deepfakes in the robustness study.\"\n        )\n\n    return {\n        \"status\": \"success\",\n        \"language\": language,\n        \"classification\": classification,\n        \"confidenceScore\": float(confidence),\n        \"explanation\": explanation,\n    }\n\n\nprint(\"Inference helpers defined. You can now wire this into your REST API.\")","metadata":{"id":"0bd5b0ef","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T17:03:25.988078Z","iopub.status.idle":"2026-01-29T17:03:25.988383Z","shell.execute_reply.started":"2026-01-29T17:03:25.988244Z","shell.execute_reply":"2026-01-29T17:03:25.988268Z"}},"outputs":[],"execution_count":null}]}